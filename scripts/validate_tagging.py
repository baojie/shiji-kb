#!/usr/bin/env python3
"""
è´¨æ§å‡½æ•°ï¼šéªŒè¯è½¬æ¢åçš„ md æ–‡ä»¶æ²¡æœ‰æ”¹åŠ¨åŸå§‹æ–‡æœ¬å†…å®¹
"""

import re
import sys
from pathlib import Path


def remove_all_tags(text):
    """å»é™¤æ‰€æœ‰è¯­ä¹‰æ ‡ç­¾å’Œç¼–å·"""
    # å»é™¤æ®µè½ç¼–å· [1], [1.1], [1.1.2] ç­‰
    text = re.sub(r'^\[\d+(?:\.\d+)*\]\s*', '', text, flags=re.MULTILINE)

    # å»é™¤ markdown æ ‡é¢˜æ ‡è®°
    text = re.sub(r'^##\s+.*$', '', text, flags=re.MULTILINE)

    # å»é™¤å¼•ç”¨å—æ ‡è®°å’Œå‰å¯¼ >
    text = re.sub(r'^>\s*', '', text, flags=re.MULTILINE)
    text = re.sub(r'^\[!NOTE\]\s+', '', text, flags=re.MULTILINE)

    # å»é™¤å„ç§è¯­ä¹‰æ ‡ç­¾ï¼ˆæŒ‰å‡ºç°é¢‘ç‡ä¼˜åŒ–é¡ºåºï¼‰
    # @person@ - äººç‰©
    text = re.sub(r'@([^@]+)@', r'\1', text)
    # &state& - å›½å®¶/ç»„ç»‡
    text = re.sub(r'&([^&]+)&', r'\1', text)
    # =place= - åœ°ç‚¹
    text = re.sub(r'=([^=]+)=', r'\1', text)
    # $position$ - èŒä½
    text = re.sub(r'\$([^$]+)\$', r'\1', text)
    # %time% - æ—¶é—´
    text = re.sub(r'%([^%]+)%', r'\1', text)
    # *object* - ç‰©å“
    text = re.sub(r'\*([^*]+)\*', r'\1', text)
    # ^concept^ - æ¦‚å¿µ (ä¿®æ­£ï¼šä¸èƒ½ç”¨ ^ï¼Œè¦ç”¨ \^)
    text = re.sub(r'\^([^\^]+)\^', r'\1', text)
    # ~tribe~ - éƒ¨è½
    text = re.sub(r'~([^~]+)~', r'\1', text)
    # ?deity? - ç¥çµ
    text = re.sub(r'\?([^?]+)\?', r'\1', text)
    # ğŸŒ¿animalğŸŒ¿ - åŠ¨æ¤ç‰©
    text = re.sub(r'ğŸŒ¿([^ğŸŒ¿]+)ğŸŒ¿', r'\1', text)
    # !event! - å¤©è±¡
    text = re.sub(r'!([^!]+)!', r'\1', text)

    return text.strip()


def get_paragraphs_from_md(md_path):
    """ä» md æ–‡ä»¶ä¸­æå–æ®µè½"""
    with open(md_path, 'r', encoding='utf-8') as f:
        content = f.read()

    # æŒ‰ç©ºè¡Œåˆ†å‰²æ®µè½
    paragraphs = []
    current_para = []

    for line in content.split('\n'):
        line = line.rstrip()
        if not line:
            if current_para:
                paragraphs.append('\n'.join(current_para))
                current_para = []
        else:
            current_para.append(line)

    if current_para:
        paragraphs.append('\n'.join(current_para))

    return paragraphs


def normalize_text(text):
    """æ ‡å‡†åŒ–æ–‡æœ¬ï¼Œç”¨äºæ¯”è¾ƒ"""
    # ç§»é™¤æ‰€æœ‰ç©ºç™½å­—ç¬¦çš„å˜åŒ–
    text = re.sub(r'\s+', '', text)
    return text


def extract_paragraph_number(para):
    """ä»æ®µè½ä¸­æå–æ®µè½ç¼–å·ï¼Œå¦‚ [1], [1.1], [1.1.2] ç­‰"""
    match = re.match(r'^\[(\d+(?:\.\d+)*)\]', para)
    if match:
        return match.group(1)
    return None


def get_root_number(para_num):
    """è·å–æ®µè½ç¼–å·çš„æ ¹ç¼–å·ï¼Œå¦‚ 1.2.3 -> 1"""
    if not para_num:
        return None
    return para_num.split('.')[0]


def validate_chapter(md_path, txt_path):
    """éªŒè¯ç« èŠ‚è½¬æ¢çš„æ­£ç¡®æ€§"""
    # è¯»å–åŸå§‹æ–‡æœ¬
    with open(txt_path, 'r', encoding='utf-8') as f:
        original_text = f.read()

    # æ¸…ç†åŸå§‹æ–‡æœ¬ï¼ˆå»é™¤æ®µè½ç¼–å·ï¼‰
    clean_original = remove_all_tags(original_text)

    # æ ‡å‡†åŒ–åŸå§‹æ–‡æœ¬
    normalized_original = normalize_text(clean_original)

    # è·å– md ä¸­çš„æ®µè½
    paragraphs = get_paragraphs_from_md(md_path)

    # æŒ‰æ®µè½ç¼–å·åˆ†ç»„
    grouped_paragraphs = {}
    for i, para in enumerate(paragraphs, 1):
        # è·³è¿‡æ ‡é¢˜è¡Œï¼ˆä»¥ # å¼€å¤´çš„ï¼‰
        if para.startswith('#'):
            continue

        # è·³è¿‡å¼•ç”¨å—çš„æ ‡è®°è¡Œ
        if para.startswith('> [!NOTE]'):
            continue

        # æå–æ®µè½ç¼–å·
        para_num = extract_paragraph_number(para)
        if para_num:
            root_num = get_root_number(para_num)
            if root_num not in grouped_paragraphs:
                grouped_paragraphs[root_num] = []
            grouped_paragraphs[root_num].append((i, para_num, para))

    errors = []
    checked_count = 0

    # éªŒè¯æ¯ç»„æ®µè½
    for root_num in sorted(grouped_paragraphs.keys(), key=lambda x: int(x)):
        group = grouped_paragraphs[root_num]

        # åˆå¹¶åŒä¸€ç»„çš„æ‰€æœ‰æ®µè½
        combined_text = ''
        for _, _, para in group:
            clean_para = remove_all_tags(para)
            if clean_para:
                combined_text += clean_para

        if not combined_text:
            continue

        checked_count += 1

        # æ ‡å‡†åŒ–åˆå¹¶åçš„æ–‡æœ¬
        normalized_combined = normalize_text(combined_text)

        # æ£€æŸ¥æ˜¯å¦åœ¨åŸå§‹æ–‡æœ¬ä¸­
        if normalized_combined not in normalized_original:
            errors.append({
                'root_num': root_num,
                'para_count': len(group),
                'para_nums': [pn for _, pn, _ in group],
                'combined': combined_text[:300] + '...' if len(combined_text) > 300 else combined_text
            })

    # æŠ¥å‘Šç»“æœ
    print(f"éªŒè¯æ–‡ä»¶: {md_path.name}")
    print(f"æ£€æŸ¥æ®µè½ç»„æ•°: {checked_count}")

    if errors:
        print(f"\nâŒ å‘ç° {len(errors)} ä¸ªä¸åŒ¹é…çš„æ®µè½ç»„:\n")
        for err in errors:
            print(f"æ®µè½ç»„ [{err['root_num']}] (åŒ…å« {err['para_count']} ä¸ªå­æ®µè½: {', '.join(['[' + pn + ']' for pn in err['para_nums']])})")
            print(f"  åˆå¹¶åæ–‡æœ¬: {err['combined']}")
            print()
        return False
    else:
        print("âœ… æ‰€æœ‰æ®µè½éªŒè¯é€šè¿‡ï¼")
        return True


if __name__ == '__main__':
    # æµ‹è¯• 005 ç« 
    base_dir = Path('/home/baojie/work/shiji-kb')
    md_file = base_dir / 'chapter_md' / '005_ç§¦æœ¬çºª.tagged.md'
    txt_file = base_dir / 'chapter_numbered' / '005_ç§¦æœ¬çºª.txt'

    if not md_file.exists():
        print(f"é”™è¯¯: MD æ–‡ä»¶ä¸å­˜åœ¨: {md_file}")
        sys.exit(1)

    if not txt_file.exists():
        print(f"é”™è¯¯: TXT æ–‡ä»¶ä¸å­˜åœ¨: {txt_file}")
        sys.exit(1)

    success = validate_chapter(md_file, txt_file)

    if not success:
        print("\néªŒè¯å¤±è´¥ï¼å­˜åœ¨æ–‡æœ¬æ”¹åŠ¨ã€‚")
        sys.exit(1)
    else:
        print("\néªŒè¯æˆåŠŸï¼è½¬æ¢æœªæ”¹åŠ¨åŸæ–‡ã€‚")
        sys.exit(0)
