#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è‡ªåŠ¨æ£€æµ‹äººååˆ«åå€™é€‰ï¼Œæ‰©å…… entity_aliases.json

ç­–ç•¥ï¼š
1. å…¨ååŒ…å«ç®€ç§°ï¼ˆå¦‚"ç§¦åº„è¥„ç‹"åŒ…å«"åº„è¥„ç‹"ï¼‰ï¼Œä¸”åŒç« èŠ‚å‡ºç°
   - åªæœ‰å½“çŸ­åå”¯ä¸€æ˜ å°„åˆ°ä¸€ä¸ªé•¿åæ—¶æ‰è‡ªåŠ¨ç¡®è®¤ï¼ˆé¿å…æ­§ä¹‰ï¼‰
2. "å¸X"å’Œ"X"çš„æ˜ å°„ï¼ˆæ®·å•†å¸ç‹ä¸“ç”¨æ¨¡å¼ï¼‰
3. åŒå§“å€™é€‰ä»…ä¾›å‚è€ƒè¾“å‡ºï¼Œä¸è‡ªåŠ¨åˆå¹¶

å®‰å…¨æªæ–½ï¼š
- è¿‡æ»¤åŒ…å«æ ‡è®°ç¬¦å·çš„åƒåœ¾æ¡ç›®
- æ’é™¤é€šç”¨ç§°è°“ï¼ˆå¤ªåã€å¤ªå­ã€å…¬å­ã€å¤«äººç­‰ï¼‰
- æ­§ä¹‰çŸ­åï¼ˆæ˜ å°„åˆ°å¤šä¸ªé•¿åï¼‰ä¸è‡ªåŠ¨ç¡®è®¤
"""

import re
import json
from pathlib import Path
from collections import defaultdict

CHAPTER_DIR = Path('chapter_md')
ALIAS_FILE = Path('entity_aliases.json')
PERSON_PATTERN = r'@([^@\n]+)@'

# æ ‡è®°ç¬¦å·ï¼Œå«è¿™äº›å­—ç¬¦çš„ä¸æ˜¯åˆæ³•äººå
INVALID_CHARS = set('$&=%~*!?ğŸŒ¿ï¼Œã€‚ã€ï¼›ï¼š""''ï¼ˆï¼‰ã€Šã€‹ã€ã€‘Â·')

# é€šç”¨ç§°è°“/èŒè¡”ï¼Œä¸èƒ½ä½œä¸ºåˆ«åï¼ˆå¤ªæ³›æ³›ï¼Œåœ¨ä¸åŒç« èŠ‚æŒ‡ä¸åŒäººï¼‰
GENERIC_TITLES = {
    'å¤ªå', 'å¤ªå­', 'å…¬å­', 'å¤«äºº', 'å°†å†›', 'ä¸ç›¸', 'å¤§å¤«',
    'çš‡å', 'ç‹å', 'å¤©å­', 'è¯¸ä¾¯', 'å¤§ç‹', 'å›', 'è‡£',
    'å¤ªå²', 'å¤ªå¸ˆ', 'å¤ªå‚…', 'å°‘å‚…', 'å¾¡å²', 'èˆäºº',
    'å…¬ä¸»', 'ç‹å­™', 'ä¸–å­',
}


def is_valid_name(name):
    """æ£€æŸ¥æ˜¯å¦æ˜¯åˆæ³•çš„äººåï¼ˆçº¯æ±‰å­—ï¼Œæ— æ ‡è®°ç¬¦å·ï¼‰"""
    if not name or len(name) < 2:
        return False
    for ch in name:
        if ch in INVALID_CHARS:
            return False
    # æ£€æŸ¥æ˜¯å¦å…¨æ˜¯æ±‰å­—ï¼ˆå…è®¸å°‘æ•°éæ±‰å­—å¦‚"Â·"å·²åœ¨INVALID_CHARSä¸­æ’é™¤ï¼‰
    for ch in name:
        if not ('\u4e00' <= ch <= '\u9fff'):
            return False
    return True


def extract_persons_by_chapter():
    """æå–æ¯ä¸ªç« èŠ‚ä¸­å‡ºç°çš„äººåé›†åˆ"""
    chapter_persons = defaultdict(set)
    person_chapters = defaultdict(set)

    for fpath in sorted(CHAPTER_DIR.glob('*.tagged.md')):
        chapter_id = fpath.stem.replace('.tagged', '')
        with open(fpath, 'r', encoding='utf-8') as f:
            content = f.read()
        for m in re.finditer(PERSON_PATTERN, content):
            name = m.group(1).strip()
            if is_valid_name(name):
                chapter_persons[chapter_id].add(name)
                person_chapters[name].add(chapter_id)

    return chapter_persons, person_chapters


def load_existing_aliases():
    """åŠ è½½ç°æœ‰åˆ«åæ˜ å°„"""
    if not ALIAS_FILE.exists():
        return set(), {}
    with open(ALIAS_FILE, 'r', encoding='utf-8') as f:
        raw = json.load(f)
    known = set()
    for canonical, aliases in raw.get('person', {}).items():
        known.add(canonical)
        for a in aliases:
            if a:
                known.add(a)
    return known, raw


def find_prefix_aliases(chapter_persons, person_chapters):
    """
    æ‰¾å…¨ååŒ…å«ç®€ç§°çš„å€™é€‰ã€‚
    å…³é”®æ”¹è¿›ï¼šæŒ‰çŸ­ååˆ†ç»„ï¼Œåªæœ‰çŸ­åå”¯ä¸€å¯¹åº”ä¸€ä¸ªé•¿åæ‰å¯è‡ªåŠ¨ç¡®è®¤ã€‚
    """
    all_names = set()
    for names in chapter_persons.values():
        all_names.update(names)

    # æŒ‰é•¿åº¦æ’åº
    names_list = sorted(all_names, key=len, reverse=True)

    # æ”¶é›†æ‰€æœ‰ (é•¿å, çŸ­å) å¯¹
    raw_pairs = []  # (long_name, short_name, common_chapter_count)
    checked = set()
    for long_name in names_list:
        if len(long_name) < 3:
            continue
        for short_name in names_list:
            if len(short_name) < 2 or len(short_name) >= len(long_name):
                continue
            if short_name == long_name:
                continue
            pair = (long_name, short_name)
            if pair in checked:
                continue
            checked.add(pair)

            # çŸ­åå¿…é¡»æ˜¯åˆæ³•äººå
            if short_name in GENERIC_TITLES:
                continue

            # æ£€æŸ¥åŒ…å«å…³ç³»
            if short_name not in long_name:
                continue

            # æ£€æŸ¥æ˜¯å¦åŒç« èŠ‚å‡ºç°
            common_chapters = person_chapters[long_name] & person_chapters[short_name]
            if not common_chapters:
                continue

            raw_pairs.append((long_name, short_name, len(common_chapters)))

    # æŒ‰çŸ­ååˆ†ç»„ï¼šçŸ­å â†’ [(é•¿å, count), ...]
    short_to_longs = defaultdict(list)
    for long_name, short_name, count in raw_pairs:
        short_to_longs[short_name].append((long_name, count))

    # åˆ†ç±»ï¼šå”¯ä¸€æ˜ å°„ vs æ­§ä¹‰æ˜ å°„
    unique_pairs = []    # å¯è‡ªåŠ¨ç¡®è®¤
    ambiguous = []       # éœ€äººå·¥ç¡®è®¤

    for short_name, longs in short_to_longs.items():
        if len(longs) == 1:
            long_name, count = longs[0]
            unique_pairs.append((long_name, short_name, count))
        else:
            ambiguous.append((short_name, longs))

    return unique_pairs, ambiguous


def find_di_prefix_aliases(person_chapters):
    """æ‰¾"å¸X"å’Œ"X"çš„å€™é€‰ï¼ˆæ®·å•†å¸ç‹æ¨¡å¼ï¼‰"""
    candidates = []
    for name in person_chapters:
        if name.startswith('å¸') and len(name) >= 3 and is_valid_name(name):
            short = name[1:]
            if short in person_chapters and is_valid_name(short):
                # ç¡®ä¿çŸ­åä¸åœ¨ GENERIC_TITLES ä¸­
                if short in GENERIC_TITLES:
                    continue
                common = person_chapters[name] & person_chapters[short]
                if common:
                    candidates.append((name, short, len(common)))
    return candidates


def find_surname_aliases(chapter_persons, person_chapters):
    """æ‰¾å…±äº«å§“æ°çš„å€™é€‰ï¼ˆä»…ä¾›å‚è€ƒï¼‰"""
    candidates = []
    all_names = set()
    for names in chapter_persons.values():
        all_names.update(names)

    by_surname = defaultdict(list)
    for name in all_names:
        if is_valid_name(name) and len(name) >= 2:
            by_surname[name[0]].append(name)

    for surname, names in by_surname.items():
        if len(names) < 2:
            continue
        for i, n1 in enumerate(names):
            for n2 in names[i+1:]:
                if n1 == n2:
                    continue
                if len(n1) > 4 or len(n2) > 4:
                    continue
                # æ’é™¤å·²æœ‰åŒ…å«å…³ç³»çš„ï¼ˆç”±prefixç­–ç•¥å¤„ç†ï¼‰
                if n1 in n2 or n2 in n1:
                    continue
                common = person_chapters[n1] & person_chapters[n2]
                if not common:
                    continue
                candidates.append((n1, n2, len(common)))

    return candidates


def merge_into_aliases(existing_raw, confirmed_pairs):
    """å°†ç¡®è®¤çš„åˆ«åå¯¹åˆå¹¶å…¥ç°æœ‰ aliases æ•°æ®"""
    person_aliases = existing_raw.get('person', {})

    # å»ºç«‹åå‘ç´¢å¼•
    reverse = {}
    for canonical, aliases in person_aliases.items():
        reverse[canonical] = canonical
        for a in aliases:
            if a:
                reverse[a] = canonical

    for long_name, short_name in confirmed_pairs:
        canon_long = reverse.get(long_name)
        canon_short = reverse.get(short_name)

        if canon_long and canon_short:
            if canon_long == canon_short:
                continue  # å·²åˆå¹¶
            continue  # ä¸¤ä¸ªéƒ½æœ‰ä¸åŒçš„è§„èŒƒåï¼Œè·³è¿‡

        if canon_long:
            canonical = canon_long
            if short_name not in person_aliases.get(canonical, []):
                person_aliases.setdefault(canonical, []).append(short_name)
                reverse[short_name] = canonical
        elif canon_short:
            canonical = canon_short
            if long_name not in person_aliases.get(canonical, []):
                person_aliases.setdefault(canonical, []).append(long_name)
                reverse[long_name] = canonical
        else:
            person_aliases[long_name] = person_aliases.get(long_name, []) + [short_name]
            reverse[long_name] = long_name
            reverse[short_name] = long_name

    existing_raw['person'] = person_aliases
    return existing_raw


def main():
    print("=" * 60)
    print("è‡ªåŠ¨æ£€æµ‹äººååˆ«åå€™é€‰ï¼ˆä¿å®ˆæ¨¡å¼ï¼‰")
    print("=" * 60)

    chapter_persons, person_chapters = extract_persons_by_chapter()
    known_aliases, existing_raw = load_existing_aliases()

    print(f"æ€»äººåæ•°: {len(person_chapters)}")
    print(f"å·²çŸ¥åˆ«åæ˜ å°„: {len(known_aliases)}")

    # ç­–ç•¥1: å…¨ååŒ…å«ç®€ç§°ï¼ˆåŒºåˆ†å”¯ä¸€/æ­§ä¹‰ï¼‰
    unique_pairs, ambiguous_pairs = find_prefix_aliases(chapter_persons, person_chapters)

    # ç­–ç•¥2: å¸X / X
    di_candidates = find_di_prefix_aliases(person_chapters)

    # åˆå¹¶å”¯ä¸€æ˜ å°„å’Œå¸Xå€™é€‰
    auto_confirmed = []

    # å¤„ç†å”¯ä¸€æ˜ å°„çš„prefixå€™é€‰
    for long_name, short_name, count in sorted(unique_pairs, key=lambda x: -x[2]):
        # è·³è¿‡å·²çŸ¥åˆ«å
        if long_name in known_aliases and short_name in known_aliases:
            continue
        auto_confirmed.append((long_name, short_name))
        print(f"  [è‡ªåŠ¨] {long_name} â† {short_name} (å…±{count}ç« )")

    # å¤„ç†å¸Xå€™é€‰ï¼ˆä¹Ÿæ£€æŸ¥å”¯ä¸€æ€§ï¼‰
    di_short_names = defaultdict(list)
    for name, short, count in di_candidates:
        di_short_names[short].append((name, count))

    for short, longs in di_short_names.items():
        if len(longs) == 1:
            name, count = longs[0]
            if name in known_aliases and short in known_aliases:
                continue
            # æ£€æŸ¥æ˜¯å¦å·²åœ¨prefixä¸­å¤„ç†
            if any(ln == name and sn == short for ln, sn in auto_confirmed):
                continue
            auto_confirmed.append((name, short))
            print(f"  [å¸X]  {name} â† {short} (å…±{count}ç« )")

    print(f"\nè‡ªåŠ¨ç¡®è®¤: {len(auto_confirmed)} å¯¹")

    if auto_confirmed:
        updated = merge_into_aliases(existing_raw, auto_confirmed)
        with open(ALIAS_FILE, 'w', encoding='utf-8') as f:
            json.dump(updated, f, ensure_ascii=False, indent=2)
        print(f"å·²æ›´æ–° {ALIAS_FILE}")

    # æ˜¾ç¤ºæ­§ä¹‰å€™é€‰ï¼ˆéœ€äººå·¥ç¡®è®¤ï¼‰
    if ambiguous_pairs:
        print(f"\næ­§ä¹‰å€™é€‰ï¼ˆçŸ­åå¯¹åº”å¤šä¸ªé•¿åï¼Œéœ€äººå·¥é€‰æ‹©ï¼‰:")
        for short_name, longs in sorted(ambiguous_pairs, key=lambda x: -sum(c for _, c in x[1]))[:40]:
            longs_str = ", ".join(f"{ln}({c}ç« )" for ln, c in sorted(longs, key=lambda x: -x[1]))
            print(f"  ? {short_name} â†’ {longs_str}")

    # æ˜¾ç¤ºåŒå§“å€™é€‰
    surname_candidates = find_surname_aliases(chapter_persons, person_chapters)
    surname_new = []
    for n1, n2, count in surname_candidates:
        if n1 in known_aliases and n2 in known_aliases:
            continue
        surname_new.append((n1, n2, count))

    if surname_new:
        print(f"\nåŒå§“å€™é€‰ï¼ˆä»…ä¾›å‚è€ƒï¼Œéœ€äººå·¥ç¡®è®¤ï¼‰:")
        for n1, n2, count in sorted(surname_new, key=lambda x: -x[2])[:30]:
            print(f"  ? {n1} / {n2} (å…±{count}ç« )")


if __name__ == '__main__':
    main()
